{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Athe-kunal/Reinforcement-learning-trading-agent-using-Google-trends-data/blob/main/Amazon_With_Google_trends_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "z_8_ziUJngZl"
   },
   "outputs": [],
   "source": [
    "#%%capture\n",
    "#!pip install yfinance\n",
    "#!pip install stockstats\n",
    "#!pip install lz4\n",
    "#!pip install alpaca_trade_api\n",
    "#!pip install trading_calendars\n",
    "#!pip install wrds\n",
    "#!pip install pyfolio\n",
    "#!pip install stable_baselines3[extra]\n",
    "#!pip3 install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ChXvSFoo5QiZ",
    "outputId": "ff099d0b-d875-47fc-c0ce-2671214b9f92"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'Reinforcement-learning-trading-agent-using-Google-trends-data' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/Athe-kunal/Reinforcement-learning-trading-agent-using-Google-trends-data.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "z4_fYWCuFzQ5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('Reinforcement-learning-trading-agent-using-Google-trends-data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MOMS4hgXoaCv",
    "outputId": "b0806682-bcb7-4c13-d82d-0c5bea63446f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RYLAB\\anaconda3\\lib\\site-packages\\pyfolio\\pos.py:26: UserWarning: Module \"zipline.assets\" not found; mutltipliers will not be applied to position notionals.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# matplotlib.use('Agg')\n",
    "import datetime\n",
    "\n",
    "%matplotlib inline\n",
    "from finrl.apps import config\n",
    "from finrl.neo_finrl.preprocessor.yahoodownloader import YahooDownloader\n",
    "from finrl.neo_finrl.preprocessor.preprocessors import FeatureEngineer, data_split\n",
    "\n",
    "from finrl.neo_finrl.env_stock_trading.StockEnvV2 import StockTradingEnvV2\n",
    "from finrl.drl_agents.stablebaselines3.models import DRLAgent,DRLEnsembleAgent\n",
    "\n",
    "\n",
    "from finrl.neo_finrl.env_stock_trading.env_stocktrading import StockTradingEnv\n",
    "from finrl.drl_agents.stablebaselines3.models import DRLAgent,DRLEnsembleAgent\n",
    "from finrl.plot import backtest_stats, backtest_plot, get_daily_return, get_baseline\n",
    "import yfinance as yf\n",
    "import sys\n",
    "import optuna\n",
    "from stable_baselines3 import PPO\n",
    "\n",
    "\n",
    "# sys.path.append('../FinRL-library')\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OGRNhnrvog_u",
    "outputId": "4d1e1eae-09d4-40a3-c991-81a86a0f60ff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Amazon_13.csv',\n",
       " 'Apple_5.csv',\n",
       " 'Bitcoin_107.csv',\n",
       " 'Dogecoin_107.csv',\n",
       " 'Ethereum_107.csv',\n",
       " 'Facebook_13.csv',\n",
       " 'Google_13.csv',\n",
       " 'Microsoft_13.csv',\n",
       " 'Pytrends_data.txt',\n",
       " 'Tesla_47.csv']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytrends_file = os.listdir(\"Pytrends\")\n",
    "pytrends_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "HCLYYMoLrpAG"
   },
   "outputs": [],
   "source": [
    "def chaikin_df(df, roll):\n",
    "    # Money flow volume\n",
    "    mfv = ((df['Close']-df['Low']) - (df['High']-df['Close'])) / \\\n",
    "        (df['High']-df['Low'])\n",
    "    mfv = mfv.fillna(0.0)\n",
    "    mfv *= df['Volume']\n",
    "    cmf = (mfv.rolling(roll, min_periods=0).sum()\n",
    "           / df['Volume'].rolling(roll, min_periods=0).sum())\n",
    "    cmf = cmf.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "    df['cmf'] = cmf\n",
    "    # df[df['CMF'] > 0]['CMF'].clip(0.05, 1)\n",
    "    # df[df['CMF'] <= 0]['CMF'].clip(-1, -0.05)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "GpSCRLvvPLax"
   },
   "outputs": [],
   "source": [
    "ticker_list = ['AMZN']\n",
    "names = ['Amazon']\n",
    "train_start_date = '2012-01-01'\n",
    "train_end_date = '2016-12-31'\n",
    "\n",
    "val_start_date = '2017-01-01'\n",
    "val_end_date = '2017-12-31'\n",
    "\n",
    "test_start_date = '2018-01-01'\n",
    "test_end_date = '2019-12-31'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "WbCD3a7XpWGH"
   },
   "outputs": [],
   "source": [
    "def fetch_data(ticker_list,names):\n",
    "    '''\n",
    "    For the ticker list, it will download, include Chaikin and Pytrends\n",
    "    Append to the dataframe\n",
    "    '''\n",
    "\n",
    "    data_df = pd.DataFrame()\n",
    "    for tic,name in zip(ticker_list,names):\n",
    "        temp_df = yf.download(tic, start=train_start_date, end=test_end_date)\n",
    "        temp_df['tic'] = tic\n",
    "        temp_df = chaikin_df(temp_df, 20)\n",
    "        temp_df = temp_df.reset_index()\n",
    "        for files in pytrends_file:\n",
    "          if files.split('_')[0] in names:\n",
    "            pytrends_df = pd.read_csv(os.getcwd()+'/Pytrends/'+files)\n",
    "            pytrends_df.columns = ['Date','pytrends']\n",
    "            temp_df['Date'] = temp_df.Date.apply(lambda x: x.strftime(\"%Y-%m-%d\"))\n",
    "            temp_df = temp_df.merge(pytrends_df,how='left',left_on='Date',right_on='Date')\n",
    "        data_df = data_df.append(temp_df)\n",
    "    # data_df = data_df.reset_index()\n",
    "    data_df.columns = [\n",
    "        \"date\",\n",
    "        \"open\",\n",
    "        \"high\",\n",
    "        \"low\",\n",
    "        \"close\",\n",
    "        \"adjcp\",\n",
    "        \"volume\",\n",
    "        \"tic\",\n",
    "        'cmf',\n",
    "        'pytrends'\n",
    "    ]\n",
    "    data_df['close'] = data_df['adjcp']\n",
    "\n",
    "    data_df = data_df.drop('adjcp',axis=1)\n",
    "\n",
    "    # data_df['day'] = data_df['date'].dt.dayofweek\n",
    "\n",
    "    # data_df['date'] = data_df.date.apply(lambda x: x.strftime(\"%Y-%m-%d\"))\n",
    "\n",
    "    \n",
    "    data_df = data_df.sort_values(by=['date','tic']).reset_index(drop=True)\n",
    "    data_df.dropna(inplace=True)\n",
    "\n",
    "    return data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Dj4mJ2-GyTPY"
   },
   "outputs": [],
   "source": [
    "def preprocess_split(start_date,end_date,ticker_list,names):\n",
    "  data_df = fetch_data(ticker_list,names)\n",
    "  fe = FeatureEngineer(\n",
    "                    use_technical_indicator=True,\n",
    "                    tech_indicator_list = config.TECHNICAL_INDICATORS_LIST,\n",
    "                    use_turbulence=False,\n",
    "                    user_defined_feature = False)\n",
    "\n",
    "  processed = fe.preprocess_data(data_df)\n",
    "  \n",
    "  # processed.to_csv(f'{names[0]}_final.csv')\n",
    "  # processed = pd.read_csv(f'{names[0]}_final.csv',index_col=[0])\n",
    "  processed['p_into_cmf'] = processed['cmf'] * processed['pytrends']\n",
    "  processed['p_into_cmf/100'] = processed['cmf'] * processed['pytrends'] / 100\n",
    "  \n",
    "  train = data_split(processed, train_start_date,train_end_date)\n",
    "  val = data_split(processed,val_start_date,val_end_date)\n",
    "  trade = data_split(processed, test_start_date,test_end_date)\n",
    "  print(len(train))\n",
    "  print(len(val))\n",
    "  print(len(trade))\n",
    "\n",
    "  return train,val,trade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "m_etGDb-RICq"
   },
   "outputs": [],
   "source": [
    "def sample_ppo_params(trial:optuna.Trial):\n",
    "  # Episode length is a categorical hyperparamter\n",
    "  n_steps = trial.suggest_categorical(\"n_steps\", [512, 1024, 2048])\n",
    "  #Entropy coefficient for exploration-exploitation\n",
    "  ent_coef = trial.suggest_loguniform(\"ent_coef\", 0.0001, 0.1)\n",
    "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1)\n",
    "  batch_size = trial.suggest_categorical(\"batch_size\", [ 64, 128, 256])\n",
    "  \n",
    "  return {\"n_steps\":n_steps,\n",
    "          \"ent_coef\":ent_coef,\n",
    "          \"learning_rate\":learning_rate,\n",
    "          \"batch_size\":batch_size}\n",
    "def calculate_sharpe(df):\n",
    "  df['daily_return'] = df['total_assets'].pct_change(1)\n",
    "  if df['daily_return'].std() !=0:\n",
    "    sharpe = (252**0.5)*df['daily_return'].mean()/ \\\n",
    "          df['daily_return'].std()\n",
    "    return sharpe\n",
    "  else:\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "KMMX2dB5zZWR"
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import os\n",
    "# ticker_list = ['AMZN','AAPL','FB','GOOGL','MSFT']\n",
    "# names = ['Amazon','Apple','Facebook','Google','Microsoft']\n",
    "total_timesteps = 30000\n",
    "os.makedirs(f'{names[0]}_acc_val',exist_ok=True)\n",
    "os.makedirs(f'{names[0]}_models',exist_ok=True)\n",
    "def train_cases():\n",
    "\n",
    "  train,val,trade = preprocess_split(train_start_date,test_end_date,ticker_list,names)\n",
    "  # ctrl_str = ['ohlcv_cmf_pytrends','ohlcv_Pytrends','ohlcv_cmf_into_pytrends','ohlcv_cmf_into_pytrends_100','ohlcv_TI']\n",
    "  ctrl_str = ['ohlcv']\n",
    "  for ctrl in ctrl_str:\n",
    "    if ctrl == 'ohlcv':\n",
    "      information_cols = ['open', 'high', 'low', 'close','volume']\n",
    "    elif ctrl == 'ohlcv_cmf_pytrends':\n",
    "      information_cols = ['open', 'high', 'low', 'close','volume','cmf','pytrends']\n",
    "    elif ctrl == 'ohlcv_cmf_into_pytrends':\n",
    "      information_cols = ['open', 'high', 'low', 'close','volume','p_into_cmf']\n",
    "    elif ctrl == 'ohlcv_cmf_into_pytrends_100':\n",
    "      information_cols = ['open', 'high', 'low', 'close','volume','p_into_cmf/100']\n",
    "    elif ctrl == 'ohlcv_TI':\n",
    "      information_cols = ['open', 'high', 'low', 'close','volume','macd','rsi_30','cci_30','dx_30'] \n",
    "    elif ctrl == 'ohlcv_Pytrends':\n",
    "      information_cols = ['open', 'high', 'low', 'close','volume','pytrends']\n",
    "      \n",
    "    e_train_gym = StockTradingEnvV2(df = train,initial_amount = 1e5,hmax = 1, \n",
    "                                  transaction_cost_pct = 0.001,\n",
    "                                  out_of_cash_penalty = 0, \n",
    "                                  cache_indicator_data=False,\n",
    "                                  cash_penalty_proportion=0, \n",
    "                                  reward_scaling=1,\n",
    "                                  daily_information_cols = information_cols, \n",
    "                                  print_verbosity = 1000, random_start = False)\n",
    "    \n",
    "    e_trade_gym = StockTradingEnvV2(df = trade,initial_amount = 1e5,hmax = 1, \n",
    "                                  out_of_cash_penalty = 0, \n",
    "                                  transaction_cost_pct = 0.001,\n",
    "                                  cash_penalty_proportion=0,\n",
    "                                  reward_scaling = 1, \n",
    "                                  cache_indicator_data=False,\n",
    "                                  daily_information_cols = information_cols, \n",
    "                                  print_verbosity = 500, random_start = False)\n",
    "    print(f'Build an environment for {ctrl}')\n",
    "    env_train, _ = e_train_gym.get_sb_env()\n",
    "    agent = DRLAgent(env = env_train)\n",
    "  \n",
    "    def objective(trial:optuna.Trial):\n",
    "      hyperparameters = sample_ppo_params(trial)\n",
    "      model_ppo = agent.get_model(\"ppo\",model_kwargs = hyperparameters)\n",
    "      trained_ppo = agent.train_model(model=model_ppo, \n",
    "                            tb_log_name='ppo',\n",
    "                            total_timesteps=total_timesteps)\n",
    "      clear_output(wait=True)\n",
    "      trained_ppo.save('{}_models/ppo_{}_{}.pth'.format(names[0],trial.number,ctrl))\n",
    "      e_val_gym = StockTradingEnvV2(df = val,initial_amount = 1e5,hmax = 1, \n",
    "                                  transaction_cost_pct = 0.001,\n",
    "                                  out_of_cash_penalty = 0, \n",
    "                                  cache_indicator_data=False,\n",
    "                                  cash_penalty_proportion=0, \n",
    "                                  reward_scaling=1,\n",
    "                                  daily_information_cols = information_cols, \n",
    "                                  print_verbosity = 1000, random_start = False)\n",
    "      df_account_value, df_actions = DRLAgent.DRL_prediction(\n",
    "                          model=trained_ppo, \n",
    "                          environment = e_val_gym)\n",
    "      sharpe = calculate_sharpe(df_account_value)\n",
    "      return sharpe\n",
    "    sampler = optuna.samplers.TPESampler()\n",
    "    study = optuna.create_study(study_name=\"ppo_study_\"+ctrl,direction='maximize',\n",
    "                          sampler = sampler, pruner=optuna.pruners.HyperbandPruner())\n",
    "\n",
    "    study.optimize(objective, n_trials=20,catch=(ValueError,))\n",
    "    tuned_model_ppo = PPO.load('{}_models/ppo_{}_{}.pth'.format(names[0],study.best_trial.number,ctrl),env=env_train)\n",
    "    df_account_value, df_actions = DRLAgent.DRL_prediction(\n",
    "                                              model=tuned_model_ppo, \n",
    "                                              environment = e_trade_gym)\n",
    "    df_account_value.to_csv(f'{names[0]}_acc_val/Account_Value_{ctrl}_{names[0]}_new.csv')\n",
    "    df_actions.to_csv(f'{names[0]}_acc_val/Action_Value_{ctrl}_{names[0]}_new.csv')  \n",
    "\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JpmLsXzHWWXV",
    "outputId": "a0883c73-69e9-439d-d853-db40b80a7d0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-24 13:54:53,927]\u001b[0m A new study created in memory with name: ppo_study_ohlcv\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added technical indicators\n",
      "1258\n",
      "251\n",
      "502\n",
      "Build an environment for ohlcv\n",
      "{'n_steps': 2048, 'ent_coef': 0.001281930056595083, 'learning_rate': 0.016648659853234972, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo\\ppo_21\n",
      "EPISODE|STEPS|TERMINAL_REASON|TOT_ASSETS|TERMINAL_REWARD_unsc|CASH_PCT  \n",
      "   1| 999|update         |$100008   |0.00001%  |99.98%    \n",
      "   1|1257|Last Date      |$100009   |0.00001%  |99.97%    \n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    fps             | 635           |\n",
      "|    iterations      | 1             |\n",
      "|    time_elapsed    | 3             |\n",
      "|    total_timesteps | 2048          |\n",
      "| train/             |               |\n",
      "|    reward          | 3.6805943e-08 |\n",
      "--------------------------------------\n",
      "   2| 999|update         |$100027   |0.00003%  |99.93%    \n",
      "   2|1257|Last Date      |$100041   |0.00003%  |99.88%    \n",
      "   3| 999|update         |$100191   |0.00019%  |99.64%    \n",
      "   3|1257|Last Date      |$100250   |0.00020%  |99.55%    \n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 580          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 7            |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.019717172  |\n",
      "|    clip_fraction        | 0.311        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.44        |\n",
      "|    explained_variance   | -2.5         |\n",
      "|    learning_rate        | 0.0166       |\n",
      "|    loss                 | -0.00284     |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | 0.0219       |\n",
      "|    reward               | 3.678785e-07 |\n",
      "|    std                  | 0.98         |\n",
      "|    value_loss           | 0.228        |\n",
      "------------------------------------------\n",
      "   4| 999|update         |$100257   |0.00026%  |99.53%    \n",
      "   4|1257|Last Date      |$100334   |0.00027%  |99.39%    \n",
      "   5| 999|update         |$100221   |0.00022%  |99.59%    \n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 570          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 10           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.07128501   |\n",
      "|    clip_fraction        | 0.259        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.42        |\n",
      "|    explained_variance   | -0.00498     |\n",
      "|    learning_rate        | 0.0166       |\n",
      "|    loss                 | 0.00735      |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | 0.00955      |\n",
      "|    reward               | 2.367634e-06 |\n",
      "|    std                  | 0.973        |\n",
      "|    value_loss           | 0.00543      |\n",
      "------------------------------------------\n",
      "   5|1257|Last Date      |$100286   |0.00023%  |99.48%    \n",
      "   6| 999|update         |$100270   |0.00027%  |99.50%    \n",
      "   6|1257|Last Date      |$100351   |0.00028%  |99.36%    \n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 561           |\n",
      "|    iterations           | 4             |\n",
      "|    time_elapsed         | 14            |\n",
      "|    total_timesteps      | 8192          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.044138804   |\n",
      "|    clip_fraction        | 0.386         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.38         |\n",
      "|    explained_variance   | -0.000264     |\n",
      "|    learning_rate        | 0.0166        |\n",
      "|    loss                 | -3.03e-05     |\n",
      "|    n_updates            | 30            |\n",
      "|    policy_gradient_loss | 0.0125        |\n",
      "|    reward               | 5.4575173e-07 |\n",
      "|    std                  | 0.942         |\n",
      "|    value_loss           | 0.00885       |\n",
      "-------------------------------------------\n",
      "   7| 999|update         |$100173   |0.00017%  |99.67%    \n",
      "   7|1257|Last Date      |$100225   |0.00018%  |99.62%    \n",
      "   8| 999|update         |$100096   |0.00010%  |99.82%    \n",
      "   8|1257|Last Date      |$100123   |0.00010%  |99.78%    \n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 555           |\n",
      "|    iterations           | 5             |\n",
      "|    time_elapsed         | 18            |\n",
      "|    total_timesteps      | 10240         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.027240891   |\n",
      "|    clip_fraction        | 0.282         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.34         |\n",
      "|    explained_variance   | 0.000564      |\n",
      "|    learning_rate        | 0.0166        |\n",
      "|    loss                 | -0.00646      |\n",
      "|    n_updates            | 40            |\n",
      "|    policy_gradient_loss | 0.013         |\n",
      "|    reward               | 1.7419659e-07 |\n",
      "|    std                  | 0.916         |\n",
      "|    value_loss           | 0.00285       |\n",
      "-------------------------------------------\n",
      "   9| 999|update         |$100009   |0.00001%  |100.00%   \n",
      "   9|1257|Last Date      |$100009   |0.00001%  |100.00%   \n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 557            |\n",
      "|    iterations           | 6              |\n",
      "|    time_elapsed         | 22             |\n",
      "|    total_timesteps      | 12288          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.009936614    |\n",
      "|    clip_fraction        | 0.261          |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.36          |\n",
      "|    explained_variance   | 0.000286       |\n",
      "|    learning_rate        | 0.0166         |\n",
      "|    loss                 | -0.0043        |\n",
      "|    n_updates            | 50             |\n",
      "|    policy_gradient_loss | 0.0101         |\n",
      "|    reward               | 1.16251035e-08 |\n",
      "|    std                  | 0.939          |\n",
      "|    value_loss           | 0.00329        |\n",
      "--------------------------------------------\n",
      "  10| 999|update         |$100001   |0.00000%  |100.00%   \n",
      "  10|1257|Last Date      |$100001   |0.00000%  |100.00%   \n",
      "  11| 999|update         |$100008   |0.00001%  |99.98%    \n",
      "  11|1257|Last Date      |$100008   |0.00001%  |100.00%   \n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 553           |\n",
      "|    iterations           | 7             |\n",
      "|    time_elapsed         | 25            |\n",
      "|    total_timesteps      | 14336         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.025323918   |\n",
      "|    clip_fraction        | 0.375         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.47         |\n",
      "|    explained_variance   | 0.000144      |\n",
      "|    learning_rate        | 0.0166        |\n",
      "|    loss                 | 0.0109        |\n",
      "|    n_updates            | 60            |\n",
      "|    policy_gradient_loss | 0.0096        |\n",
      "|    reward               | 4.5784937e-08 |\n",
      "|    std                  | 1.04          |\n",
      "|    value_loss           | 0.00159       |\n",
      "-------------------------------------------\n",
      "  12| 999|update         |$100002   |0.00000%  |99.99%    \n",
      "  12|1257|Last Date      |$100004   |0.00000%  |100.00%   \n",
      "  13| 999|update         |$100005   |0.00001%  |99.99%    \n",
      "  13|1257|Last Date      |$100006   |0.00001%  |99.99%    \n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 553           |\n",
      "|    iterations           | 8             |\n",
      "|    time_elapsed         | 29            |\n",
      "|    total_timesteps      | 16384         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.041520465   |\n",
      "|    clip_fraction        | 0.262         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.43         |\n",
      "|    explained_variance   | 0.000223      |\n",
      "|    learning_rate        | 0.0166        |\n",
      "|    loss                 | 0.0172        |\n",
      "|    n_updates            | 70            |\n",
      "|    policy_gradient_loss | 0.00715       |\n",
      "|    reward               | 1.3032485e-07 |\n",
      "|    std                  | 1.04          |\n",
      "|    value_loss           | 0.0151        |\n",
      "-------------------------------------------\n",
      "  14| 999|update         |$100009   |0.00001%  |99.99%    \n",
      "  14|1257|Last Date      |$100008   |0.00001%  |99.99%    \n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 550          |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 33           |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.007974269  |\n",
      "|    clip_fraction        | 0.313        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.45        |\n",
      "|    explained_variance   | -0.163       |\n",
      "|    learning_rate        | 0.0166       |\n",
      "|    loss                 | 0.0129       |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | 0.0143       |\n",
      "|    reward               | 4.344257e-08 |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 0.00572      |\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "train_cases()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 276
    },
    "id": "Yo1IfusxqYq3",
    "outputId": "5b31637f-598c-4577-916f-afa2a9edf763"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "account_value_files = os.listdir(f'{names[0]}_acc_val')\n",
    "sharpe_values = {}\n",
    "for files in account_value_files:\n",
    "  if files.split(\"_\")[0] == 'Account':\n",
    "      df = pd.read_csv(f'{names[0]}_acc_val/'+files)\n",
    "      name = files.split(\".\")[0][:-4]\n",
    "      sharpe_values[name] = calculate_sharpe(df)\n",
    "      plt.plot(df['total_assets'], label=name)\n",
    "      plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ImzkzB8IiKQg",
    "outputId": "5bbe4700-e93d-4f58-be86-50ca756745cf"
   },
   "outputs": [],
   "source": [
    "print(sharpe_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPhDiU5ltdf5wfec74yVTfv",
   "collapsed_sections": [],
   "include_colab_link": true,
   "mount_file_id": "1D0zQhj3cz-EVoYYsK5eAWUo_VBilFFrM",
   "name": "Amazon With Google trends data",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
